{"cells":[{"cell_type":"markdown","metadata":{"id":"pgFYFftQKxY5"},"source":["<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:450px;\" width=500/></p>\n","\n","<h3 style=\"text-align: center;\"><b>Школа глубокого обучения ФПМИ МФТИ</b></h3>\n","<h3 style=\"text-align: center;\"><b>Базовый и продвинутый потоки. Осень 2021</b></h3>\n","\n","<h1 style=\"text-align: center;\"><b>Домашнее задание. Библиотека sklearn и классификация с помощью KNN</b></h1>"]},{"cell_type":"markdown","metadata":{"id":"v4RCHGZULaWz"},"source":["На основе [курса по Машинному Обучению ФИВТ МФТИ](https://github.com/ml-mipt/ml-mipt) и [Открытого курса по Машинному Обучению](https://habr.com/ru/company/ods/blog/322626/)."]},{"cell_type":"markdown","metadata":{"id":"F2acNQu1L94J"},"source":["---"]},{"cell_type":"markdown","metadata":{"id":"Twe_cnn5KxY6"},"source":["<h2 style=\"text-align: center;\"><b>K Nearest Neighbors (KNN)</b></h2>"]},{"cell_type":"markdown","metadata":{"id":"YD0NXyUYKxY7"},"source":["Метод ближайших соседей (k Nearest Neighbors, или kNN) — очень популярный метод классификации, также иногда используемый в задачах регрессии. Это один из самых понятных подходов к классификации. На уровне интуиции суть метода такова: посмотри на соседей; какие преобладают --- таков и ты. Формально основой метода является гипотеза компактности: если метрика расстояния между примерами введена достаточно удачно, то схожие примеры гораздо чаще лежат в одном классе, чем в разных. "]},{"cell_type":"markdown","metadata":{"id":"CTa2jNZkKxY8"},"source":["<img src='https://hsto.org/web/68d/a45/6f0/68da456f00f8434e87628dbe7e3f54a7.png' width=600>"]},{"cell_type":"markdown","metadata":{"id":"5H7wPU0IKxY-"},"source":["\n","Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить следующие операции:\n","\n","* Вычислить расстояние до каждого из объектов обучающей выборки\n","* Отобрать объектов обучающей выборки, расстояние до которых минимально\n","* Класс классифицируемого объекта — это класс, наиболее часто встречающийся среди $k$ ближайших соседей"]},{"cell_type":"markdown","metadata":{"id":"T2docs4225pb"},"source":["Будем работать с подвыборкой из [данных о типе лесного покрытия из репозитория UCI](http://archive.ics.uci.edu/ml/datasets/Covertype). Доступно 7 различных классов. Каждый объект описывается 54 признаками, 40 из которых являются бинарными. Описание данных доступно по ссылке."]},{"cell_type":"markdown","metadata":{"id":"AcjJQX3wKxZA"},"source":["### Обработка данных"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"Ozcx5mVOKxZB"},"outputs":[],"source":["import pandas as pd\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"Ry4bMKaUjHJj"},"source":["Сcылка на датасет (лежит в папке): https://drive.google.com/drive/folders/16TSz1P-oTF8iXSQ1xrt0r_VO35xKmUes?usp=sharing"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"rvPrVRvK25pc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>45</th>\n","      <th>46</th>\n","      <th>47</th>\n","      <th>48</th>\n","      <th>49</th>\n","      <th>50</th>\n","      <th>51</th>\n","      <th>52</th>\n","      <th>53</th>\n","      <th>54</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2683</td>\n","      <td>333</td>\n","      <td>35</td>\n","      <td>30</td>\n","      <td>26</td>\n","      <td>2743</td>\n","      <td>121</td>\n","      <td>173</td>\n","      <td>179</td>\n","      <td>6572</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2915</td>\n","      <td>90</td>\n","      <td>8</td>\n","      <td>216</td>\n","      <td>11</td>\n","      <td>4433</td>\n","      <td>232</td>\n","      <td>228</td>\n","      <td>129</td>\n","      <td>4019</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2941</td>\n","      <td>162</td>\n","      <td>7</td>\n","      <td>698</td>\n","      <td>76</td>\n","      <td>2783</td>\n","      <td>227</td>\n","      <td>242</td>\n","      <td>148</td>\n","      <td>1784</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3096</td>\n","      <td>60</td>\n","      <td>17</td>\n","      <td>170</td>\n","      <td>3</td>\n","      <td>3303</td>\n","      <td>231</td>\n","      <td>202</td>\n","      <td>99</td>\n","      <td>5370</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2999</td>\n","      <td>66</td>\n","      <td>8</td>\n","      <td>488</td>\n","      <td>37</td>\n","      <td>1532</td>\n","      <td>228</td>\n","      <td>225</td>\n","      <td>131</td>\n","      <td>2290</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 55 columns</p>\n","</div>"],"text/plain":["      0    1   2    3   4     5    6    7    8     9  ...  45  46  47  48  49  \\\n","0  2683  333  35   30  26  2743  121  173  179  6572  ...   0   0   0   0   0   \n","1  2915   90   8  216  11  4433  232  228  129  4019  ...   0   0   0   0   0   \n","2  2941  162   7  698  76  2783  227  242  148  1784  ...   0   0   0   0   0   \n","3  3096   60  17  170   3  3303  231  202   99  5370  ...   0   0   0   0   0   \n","4  2999   66   8  488  37  1532  228  225  131  2290  ...   0   0   0   0   0   \n","\n","   50  51  52  53  54  \n","0   0   0   0   0   2  \n","1   0   0   0   0   1  \n","2   0   0   0   0   2  \n","3   0   0   0   0   1  \n","4   0   0   0   0   2  \n","\n","[5 rows x 55 columns]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["all_data = pd.read_csv('forest_dataset.csv')\n","all_data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"_o8yXBPSKxZI"},"outputs":[{"data":{"text/plain":["(10000, 55)"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["all_data.shape"]},{"cell_type":"markdown","metadata":{"id":"itCWxHEY25pg"},"source":["Выделим значения метки класса в переменную `labels`, признаковые описания --- в переменную `feature_matrix`. Так как данные числовые и не имеют пропусков, переведем их в `numpy`-формат с помощью метода `.values`."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"f_YIUOuV25ph"},"outputs":[],"source":["labels = all_data[all_data.columns[-1]].values\n","feature_matrix = all_data[all_data.columns[:-1]].values"]},{"cell_type":"markdown","metadata":{"id":"FukXaH_r8PMQ"},"source":["### Пара слов о sklearn"]},{"cell_type":"markdown","metadata":{"id":"k5S_0Lfc8PMR"},"source":["**[sklearn](https://scikit-learn.org/stable/index.html)** -- удобная библиотека для знакомства с машинным обучением. В ней реализованны большинство стандартных алгоритмов для построения моделей и работ с выборками. У неё есть подробная документация на английском, с которой вам придётся поработать."]},{"cell_type":"markdown","metadata":{"id":"VhVDEG538PMS"},"source":["`sklearn` предпологает, что ваши выборки имеют вид пар $(X, y)$, где $X$ -- матрица признаков, $y$ -- вектор истинных значений целевой переменной, или просто $X$, если целевые переменные неизвестны."]},{"cell_type":"markdown","metadata":{"id":"QJZQulsp8PMT"},"source":["Познакомимся со вспомогательной функцией \n","[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n","С её помощью можно разбить выборку на обучающую и тестовую части."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Q030jzyY25pl"},"outputs":[],"source":["from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","metadata":{"id":"UkeB47mX8PMY"},"source":["Вернёмся к датасету. Сейчас будем работать со всеми 7 типами покрытия (данные уже находятся в переменных `feature_matrix` и `labels`, если Вы их не переопределили). Разделим выборку на обучающую и тестовую с помощью метода `train_test_split`."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"YJN0jFARKxZX"},"outputs":[],"source":["train_feature_matrix, test_feature_matrix, train_labels, test_labels = train_test_split(\n","    feature_matrix, labels, test_size=0.2, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"odC1c7X48PMb"},"source":["Параметр `test_size` контролирует, какая часть выборки будет тестовой. Более подробно о нём можно прочитать в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."]},{"cell_type":"markdown","metadata":{"id":"z3fGvPqG8PMc"},"source":["Основные объекты `sklearn` -- так называемые `estimators`, что можно перевести как *оценщики*, но не стоит, так как по сути это *модели*. Они делятся на **классификаторы** и **регрессоры**.\n","\n","В качестве примера модели можно привести классификаторы\n","[метод ближайших соседей](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) и \n","[логистическую регрессию](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Что такое логистическая регрессия и как она работает сейчас не важно."]},{"cell_type":"markdown","metadata":{"id":"IuX8Rc7c8PMd"},"source":["У всех моделей в `sklearn` обязательно должно быть хотя бы 2 метода (подробнее о методах и классах в python будет в следующих занятиях) -- `fit` и `predict`."]},{"cell_type":"markdown","metadata":{"id":"ZYokUkxO8PMe"},"source":["\n","Метод `fit(X, y)` отвечает за обучение модели и принимает на вход обучающую выборку в виде *матрицы признаков* $X$ и *вектора ответов* $y$.\n","\n","У обученной после `fit` модели теперь можно вызывать метод `predict(X)`, который вернёт предсказания этой модели на всех объектах из матрицы $X$ в виде вектора.\n","\n","Вызывать `fit` у одной и той же модели можно несколько раз, каждый раз она будет обучаться заново на переданном наборе данных.\n","\n","Ещё у моделей есть *гиперпараметры*, которые обычно задаются при создании модели.\n","\n","Рассмотрим всё это на примере логистической регрессии."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ew0Ji_2D8PMe"},"outputs":[],"source":["from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"c9KcMHXr8PMh"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  n_iter_i = _check_optimize_result(\n"]}],"source":["# создание модели с указанием гиперпараметра C\n","clf = LogisticRegression(C=1)\n","# обучение модели\n","clf.fit(train_feature_matrix, train_labels)\n","# предсказание на тестовой выборке\n","y_pred = clf.predict(test_feature_matrix)"]},{"cell_type":"markdown","metadata":{"id":"h3gjg3pm8PMm"},"source":["Теперь хотелось бы измерить качество нашей модели. Для этого можно использовать метод `score(X, y)`, который посчитает какую-то функцию ошибки на выборке $X, y$, но какую конкретно уже зависит от модели. Также можно использовать одну из функций модуля `metrics`, например [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html), которая, как понятно из названия, вычислит нам точность предсказаний."]},{"cell_type":"code","execution_count":9,"metadata":{"id":"J2Ej1Lni8PMn"},"outputs":[{"data":{"text/plain":["0.6075"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.metrics import accuracy_score\n","\n","accuracy_score(test_labels, y_pred)"]},{"cell_type":"markdown","metadata":{"id":"malIDW_P8PMp"},"source":["Наконец, последним, о чём хотелось бы упомянуть, будет перебор гиперпараметров по сетке. Так как у моделей есть много гиперпараметров, которые можно изменять, и от этих гиперпараметров существенно зависит качество модели, хотелось бы найти наилучшие в этом смысле параметры. Самый простой способ это сделать -- просто перебрать все возможные варианты в разумных пределах.\n","\n","Сделать это можно с помощью класса [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), который осуществляет поиск (search) по сетке (grid) и вычисляет качество модели с помощью кросс-валидации (CV).\n","\n","У логистической регрессии, например, можно поменять параметры `C` и `penalty`. Сделаем это. Учтите, что поиск может занять долгое время. Смысл параметров смотрите в документации."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"vq687Aoc8PMq"},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"OVnqHBvK8PMs"},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l1; total time=   4.9s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l1; total time=   4.9s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l2; total time=   3.4s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l2; total time=   3.6s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l2; total time=   3.5s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l2; total time=   3.5s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=1, penalty=l2; total time=   3.4s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l1; total time=   5.2s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l1; total time=   5.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l1; total time=   5.2s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l1; total time=   5.1s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=2, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=3, penalty=l2; total time=   3.4s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l1; total time=   5.0s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l2; total time=   3.3s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l2; total time=   3.4s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["[CV] END ....................................C=4, penalty=l2; total time=   3.4s\n","{'C': 1, 'penalty': 'l1'}\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Aleksey\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n","  warnings.warn(\n"]}],"source":["# заново создадим модель, указав солвер\n","clf = LogisticRegression(solver='saga')\n","\n","# опишем сетку, по которой будем искать\n","param_grid = {\n","    'C': np.arange(1, 5), # также можно указать обычный массив, [1, 2, 3, 4]\n","    'penalty': ['l1', 'l2'],\n","}\n","\n","# создадим объект GridSearchCV\n","search = GridSearchCV(clf, param_grid, n_jobs=1, verbose=2, cv=5, refit=True, scoring='accuracy')\n","\n","# запустим поиск\n","search.fit(feature_matrix, labels)\n","\n","# выведем наилучшие параметры\n","print(search.best_params_)"]},{"cell_type":"markdown","metadata":{"id":"DnVTFcvZ8PMv"},"source":["В данном случае, поиск перебирает все возможные пары значений C и penalty из заданных множеств."]},{"cell_type":"code","execution_count":18,"metadata":{"id":"ArKINrE_8PMw"},"outputs":[{"data":{"text/plain":["0.6419"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(labels, search.best_estimator_.predict(feature_matrix))"]},{"cell_type":"markdown","metadata":{"id":"okzpKY_I8PMz"},"source":["Заметьте, что мы передаём в GridSearchCV всю выборку, а не только её обучающую часть. Это можно делать, так как поиск всё равно использует кроссвалидацию. Однако порой от выборки всё-же отделяют *валидационную* часть, так как гиперпараметры в процессе поиска могли переобучиться под выборку."]},{"cell_type":"markdown","metadata":{"id":"_mdJyxdo8PM1"},"source":["В заданиях вам предстоит повторить это для метода ближайших соседей."]},{"cell_type":"markdown","metadata":{"id":"z8W__017KxZc"},"source":["### Обучение модели"]},{"cell_type":"markdown","metadata":{"id":"02uT6CPYKxZe"},"source":["Качество классификации/регрессии методом ближайших соседей зависит от нескольких параметров:\n","\n","* число соседей `n_neighbors`\n","* метрика расстояния между объектами `metric`\n","* веса соседей (соседи тестового примера могут входить с разными весами, например, чем дальше пример, тем с меньшим коэффициентом учитывается его \"голос\") `weights`\n"]},{"cell_type":"markdown","metadata":{"id":"BHVNCaJ325qD"},"source":["Обучите на датасете `KNeighborsClassifier` из `sklearn`."]},{"cell_type":"code","execution_count":19,"metadata":{"id":"o4CMnnOY25qD"},"outputs":[{"data":{"text/plain":["0.7365"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import accuracy_score\n","\n","clf = KNeighborsClassifier()# Ваш код здесь\n","clf.fit(train_feature_matrix, train_labels)\n","\n","y_pred = clf.predict(test_feature_matrix)\n","accuracy_score(test_labels, y_pred)\n","# Ваш код здесь"]},{"cell_type":"markdown","metadata":{"id":"r_2Mf8BiKxZk"},"source":["### Вопрос 1:\n","* Какое качество у вас получилось?"]},{"cell_type":"markdown","metadata":{"id":"uFTIaPdrKxZl"},"source":["Подберём параметры нашей модели"]},{"cell_type":"markdown","metadata":{"id":"8WzoRJZd25qF"},"source":["* Переберите по сетке от `1` до `10` параметр числа соседей\n","\n","* Также вы попробуйте использоввать различные метрики: `['manhattan', 'euclidean']`\n","\n","* Попробуйте использовать различные стратегии вычисления весов: `[‘uniform’, ‘distance’]`"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"4lMSy-6f25qG","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fitting 5 folds for each of 40 candidates, totalling 200 fits\n","[CV 1/5] END metric=manhattan, n_neighbors=1, weights=uniform;, score=0.774 total time=   1.0s\n","[CV 2/5] END metric=manhattan, n_neighbors=1, weights=uniform;, score=0.765 total time=   0.8s\n","[CV 3/5] END metric=manhattan, n_neighbors=1, weights=uniform;, score=0.774 total time=   0.7s\n","[CV 4/5] END metric=manhattan, n_neighbors=1, weights=uniform;, score=0.753 total time=   0.8s\n","[CV 5/5] END metric=manhattan, n_neighbors=1, weights=uniform;, score=0.764 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=1, weights=distance;, score=0.774 total time=   0.7s\n","[CV 2/5] END metric=manhattan, n_neighbors=1, weights=distance;, score=0.765 total time=   0.7s\n","[CV 3/5] END metric=manhattan, n_neighbors=1, weights=distance;, score=0.774 total time=   0.7s\n","[CV 4/5] END metric=manhattan, n_neighbors=1, weights=distance;, score=0.753 total time=   0.7s\n","[CV 5/5] END metric=manhattan, n_neighbors=1, weights=distance;, score=0.764 total time=   0.7s\n","[CV 1/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.736 total time=   0.8s\n","[CV 2/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.728 total time=   0.8s\n","[CV 3/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.737 total time=   0.8s\n","[CV 4/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.731 total time=   0.8s\n","[CV 5/5] END metric=manhattan, n_neighbors=2, weights=uniform;, score=0.724 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.774 total time=   0.8s\n","[CV 2/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.765 total time=   0.7s\n","[CV 3/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.774 total time=   0.7s\n","[CV 4/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.753 total time=   0.7s\n","[CV 5/5] END metric=manhattan, n_neighbors=2, weights=distance;, score=0.765 total time=   0.7s\n","[CV 1/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.752 total time=   0.7s\n","[CV 2/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.733 total time=   0.8s\n","[CV 3/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.749 total time=   0.8s\n","[CV 4/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.744 total time=   0.7s\n","[CV 5/5] END metric=manhattan, n_neighbors=3, weights=uniform;, score=0.751 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.774 total time=   0.7s\n","[CV 2/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.751 total time=   0.8s\n","[CV 3/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.770 total time=   0.8s\n","[CV 4/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.758 total time=   0.8s\n","[CV 5/5] END metric=manhattan, n_neighbors=3, weights=distance;, score=0.763 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.734 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.721 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.742 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.733 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=4, weights=uniform;, score=0.739 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.772 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.751 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.778 total time=   0.8s\n","[CV 4/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.761 total time=   0.8s\n","[CV 5/5] END metric=manhattan, n_neighbors=4, weights=distance;, score=0.772 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.751 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.731 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.744 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.742 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=5, weights=uniform;, score=0.752 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.772 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.758 total time=   0.8s\n","[CV 3/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.771 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.763 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=5, weights=distance;, score=0.767 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.743 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.723 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.736 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.724 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=6, weights=uniform;, score=0.734 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.764 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.763 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.772 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.759 total time=   0.8s\n","[CV 5/5] END metric=manhattan, n_neighbors=6, weights=distance;, score=0.767 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.741 total time=   1.0s\n","[CV 2/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.729 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.733 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.726 total time=   1.0s\n","[CV 5/5] END metric=manhattan, n_neighbors=7, weights=uniform;, score=0.745 total time=   1.0s\n","[CV 1/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.772 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.754 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.762 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.751 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=7, weights=distance;, score=0.770 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.738 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.725 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.726 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.721 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=8, weights=uniform;, score=0.751 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.769 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.764 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.766 total time=   0.8s\n","[CV 4/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.751 total time=   0.8s\n","[CV 5/5] END metric=manhattan, n_neighbors=8, weights=distance;, score=0.774 total time=   0.8s\n","[CV 1/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.737 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.732 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.726 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.722 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=9, weights=uniform;, score=0.751 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.764 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.761 total time=   0.8s\n","[CV 3/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.753 total time=   0.8s\n","[CV 4/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.756 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=9, weights=distance;, score=0.775 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.736 total time=   0.9s\n","[CV 2/5] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.727 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.720 total time=   1.0s\n","[CV 4/5] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.718 total time=   1.0s\n","[CV 5/5] END metric=manhattan, n_neighbors=10, weights=uniform;, score=0.740 total time=   0.9s\n","[CV 1/5] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.770 total time=   0.8s\n","[CV 2/5] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.760 total time=   0.9s\n","[CV 3/5] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.764 total time=   0.9s\n","[CV 4/5] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.749 total time=   0.9s\n","[CV 5/5] END metric=manhattan, n_neighbors=10, weights=distance;, score=0.765 total time=   0.8s\n","[CV 1/5] END metric=euclidean, n_neighbors=1, weights=uniform;, score=0.763 total time=   0.2s\n","[CV 2/5] END metric=euclidean, n_neighbors=1, weights=uniform;, score=0.758 total time=   0.2s\n","[CV 3/5] END metric=euclidean, n_neighbors=1, weights=uniform;, score=0.762 total time=   0.2s\n","[CV 4/5] END metric=euclidean, n_neighbors=1, weights=uniform;, score=0.752 total time=   0.2s\n","[CV 5/5] END metric=euclidean, n_neighbors=1, weights=uniform;, score=0.749 total time=   0.2s\n","[CV 1/5] END metric=euclidean, n_neighbors=1, weights=distance;, score=0.763 total time=   0.1s\n","[CV 2/5] END metric=euclidean, n_neighbors=1, weights=distance;, score=0.758 total time=   0.2s\n","[CV 3/5] END metric=euclidean, n_neighbors=1, weights=distance;, score=0.762 total time=   0.1s\n","[CV 4/5] END metric=euclidean, n_neighbors=1, weights=distance;, score=0.752 total time=   0.1s\n","[CV 5/5] END metric=euclidean, n_neighbors=1, weights=distance;, score=0.749 total time=   0.2s\n","[CV 1/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.724 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.705 total time=   0.2s\n","[CV 3/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.730 total time=   0.2s\n","[CV 4/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.737 total time=   0.2s\n","[CV 5/5] END metric=euclidean, n_neighbors=2, weights=uniform;, score=0.714 total time=   0.2s\n","[CV 1/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.763 total time=   0.2s\n","[CV 2/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.758 total time=   0.2s\n","[CV 3/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.762 total time=   0.2s\n","[CV 4/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.752 total time=   0.2s\n","[CV 5/5] END metric=euclidean, n_neighbors=2, weights=distance;, score=0.749 total time=   0.2s\n","[CV 1/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.740 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.728 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.751 total time=   0.2s\n","[CV 4/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.740 total time=   0.2s\n","[CV 5/5] END metric=euclidean, n_neighbors=3, weights=uniform;, score=0.739 total time=   0.2s\n","[CV 1/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.762 total time=   0.2s\n","[CV 2/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.745 total time=   0.2s\n","[CV 3/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.774 total time=   0.2s\n","[CV 4/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.757 total time=   0.2s\n","[CV 5/5] END metric=euclidean, n_neighbors=3, weights=distance;, score=0.752 total time=   0.2s\n","[CV 1/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.723 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.709 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.729 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.722 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=4, weights=uniform;, score=0.728 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.757 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.746 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.767 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.751 total time=   0.3s\n","[CV 5/5] END metric=euclidean, n_neighbors=4, weights=distance;, score=0.753 total time=   0.3s\n","[CV 1/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.730 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.718 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.731 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.721 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=5, weights=uniform;, score=0.728 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.749 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.739 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.766 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.741 total time=   0.3s\n","[CV 5/5] END metric=euclidean, n_neighbors=5, weights=distance;, score=0.751 total time=   0.3s\n","[CV 1/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.738 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.708 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.716 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.708 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=6, weights=uniform;, score=0.717 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.755 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.743 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.764 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.745 total time=   0.3s\n","[CV 5/5] END metric=euclidean, n_neighbors=6, weights=distance;, score=0.750 total time=   0.3s\n","[CV 1/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.721 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.714 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.714 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.713 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=7, weights=uniform;, score=0.726 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.751 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.747 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.744 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.733 total time=   0.3s\n","[CV 5/5] END metric=euclidean, n_neighbors=7, weights=distance;, score=0.745 total time=   0.3s\n","[CV 1/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.715 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.712 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.718 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.701 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=8, weights=uniform;, score=0.712 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.751 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.747 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.752 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.731 total time=   0.3s\n","[CV 5/5] END metric=euclidean, n_neighbors=8, weights=distance;, score=0.752 total time=   0.3s\n","[CV 1/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.724 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.698 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.714 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.699 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=9, weights=uniform;, score=0.721 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.747 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.743 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.751 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.728 total time=   0.3s\n","[CV 5/5] END metric=euclidean, n_neighbors=9, weights=distance;, score=0.743 total time=   0.3s\n","[CV 1/5] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.716 total time=   0.4s\n","[CV 2/5] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.698 total time=   0.4s\n","[CV 3/5] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.712 total time=   0.4s\n","[CV 4/5] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.701 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=10, weights=uniform;, score=0.708 total time=   0.4s\n","[CV 1/5] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.749 total time=   0.3s\n","[CV 2/5] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.743 total time=   0.3s\n","[CV 3/5] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.756 total time=   0.3s\n","[CV 4/5] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.731 total time=   0.4s\n","[CV 5/5] END metric=euclidean, n_neighbors=10, weights=distance;, score=0.743 total time=   0.3s\n"]},{"data":{"text/plain":["GridSearchCV(cv=5, estimator=KNeighborsClassifier(), n_jobs=1,\n","             param_grid={'metric': ['manhattan', 'euclidean'],\n","                         'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10]),\n","                         'weights': ['uniform', 'distance']},\n","             scoring='accuracy', verbose=5)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.model_selection import GridSearchCV\n","\n","params = {'n_neighbors': np.arange(1,11),\n","    'metric': ['manhattan', 'euclidean'],\n","    'weights': ['uniform', 'distance']\n","}\n","# Ваш код здесь\n","\n","clf_grid = GridSearchCV(clf, params, cv=5, scoring='accuracy', n_jobs=1, verbose=5)\n","clf_grid.fit(train_feature_matrix, train_labels)\n","# Теперь обучение. Ваш код здесь"]},{"cell_type":"markdown","metadata":{"id":"SO7E6G8jKxZp"},"source":["Выведем лучшие параметры"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"md48pHrMKxZq"},"outputs":[{"data":{"text/plain":["{'metric': 'manhattan', 'n_neighbors': 4, 'weights': 'distance'}"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["clf_grid.best_params_"]},{"cell_type":"markdown","metadata":{"id":"M05n9l8pKxZt"},"source":["### Вопрос 2:\n","* Какую metric следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"Pmjx38OoKxZt"},"source":["### Вопрос 3:\n","* Сколько n_neighbors следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"eqLeJUP8KxZu"},"source":["### Вопрос 4:\n","* Какой тип weights следует использовать?"]},{"cell_type":"markdown","metadata":{"id":"aBmiDbvV25qI"},"source":["Используя найденное оптимальное число соседей, вычислите вероятности принадлежности к классам для тестовой выборки (`.predict_proba`)."]},{"cell_type":"code","execution_count":24,"metadata":{"id":"ig_vS8O925qI"},"outputs":[],"source":["optimal_clf = KNeighborsClassifier(n_neighbors=4, metric='manhattan', weights='distance')# Ваш код здесь\n","optimal_clf.fit(train_feature_matrix, train_labels)\n","pred_prob = optimal_clf.predict(test_feature_matrix)# Ваш код здесь"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["0.785"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["accuracy_score(pred_prob, test_labels)"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"2kkapT38KxZz"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 720x576 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","import numpy as np\n","\n","unique, freq = np.unique(test_labels, return_counts=True)\n","freq = list(map(lambda x: x / len(test_labels),freq))\n","\n","pred_freq = pred_prob.mean(axis=0)\n","plt.figure(figsize=(10, 8))\n","plt.bar(range(1, 8), pred_freq, width=0.4, align=\"edge\", label='prediction')\n","plt.bar(range(1, 8), freq, width=-0.4, align=\"edge\", label='real')\n","plt.ylim(0, 0.54)\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"gp4uDyLmKxZ3"},"source":["### Вопрос 5:\n","* Какая прогнозируемая вероятность pred_freq класса под номером 3 (до 2 знаков после запятой)?"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["0.0055"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["freq[3]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"[homework,adv]knn.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
